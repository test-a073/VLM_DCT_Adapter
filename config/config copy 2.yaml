models:
  - name: florence

datasets:
  - name: chart_qa
  # - name: ok_vqa
  # - name: coco_captions

adapter:
  do_adapt: true
  do_peft: false
  name: MyCustomAdapter
  params:
    input_dim: 768
    num_components: 128
  
  layers: 
    - name: language_model.model.encoder.layers.5.self_attn.v_proj # current highest acc
    - name: language_model.model.encoder.layers.4.self_attn.v_proj
    - name: language_model.model.encoder.layers.3.self_attn.v_proj
    - name: language_model.model.encoder.layers.2.self_attn.v_proj
    - name: language_model.model.encoder.layers.1.self_attn.v_proj
    - name: language_model.model.encoder.layers.0.self_attn.v_proj

    # - name: language_model.model.encoder.layers.5.self_attn.k_proj # current highest acc
    # - name: language_model.model.encoder.layers.4.self_attn.k_proj
    # - name: language_model.model.encoder.layers.3.self_attn.k_proj
    # - name: language_model.model.encoder.layers.2.self_attn.k_proj
    # - name: language_model.model.encoder.layers.1.self_attn.k_proj
    # - name: language_model.model.encoder.layers.0.self_attn.k_proj
    # - name: language_model.model.encoder.layers.1.self_attn.v_proj

    # - name: model.layers.25.input_layernorm
    # - name: model.layers.24.input_layernorm

train:
  do_train: true
  epochs: 100
  batch_size: 1
  lr: 0.0001