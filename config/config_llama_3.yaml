adapter:
  do_adapt: true
  do_peft: false
  name: MyCustomAdapter
  params:
    # input_dim: 768 # this for florence base
    input_dim: 4096 
    num_components: 512
  
  layers: 
    # FOR MISTRAL MODEL 
    - name: model.layers.31.self_attn.q_proj
    - name: model.layers.31.self_attn.k_proj
    - name: model.layers.31.self_attn.v_proj 
    - name: model.layers.31.self_attn.o_proj
    # - name: lm_head

train:
  do_train: true
  epochs: 100
  batch_size: 1
  lr: 0.0001
  num_workers: 0