models:
  - name: florence-large
  # - name: None

datasets:
  # - name: chart_qa
  - name: gqa
  # - name: ok_vqa
  # - name: coco_captions

task_prompt: <GQA>
  
adapter:
  do_adapt: true
  do_peft: false
  name: MyCustomAdapter
  params:
    # input_dim: 768 # this for florence base
    input_dim: 1024 
    num_components: 128
  
  layers: 
    - name: language_model.model.encoder.layers.5.self_attn.v_proj # current highest acc v2
    - name: language_model.model.encoder.layers.4.self_attn.v_proj
    - name: language_model.model.encoder.layers.3.self_attn.v_proj
    - name: language_model.model.encoder.layers.2.self_attn.v_proj
    - name: language_model.model.encoder.layers.1.self_attn.v_proj
    - name: language_model.model.encoder.layers.0.self_attn.v_proj

    - name: language_model.model.decoder.layers.5.self_attn.v_proj
    - name: language_model.model.decoder.layers.4.self_attn.v_proj
    - name: language_model.model.decoder.layers.3.self_attn.v_proj
    - name: language_model.model.decoder.layers.2.self_attn.v_proj
    - name: language_model.model.decoder.layers.1.self_attn.v_proj
    - name: language_model.model.decoder.layers.0.self_attn.v_proj
    # current highest acc v2

    # - name: q_proj
    # - name: v_proj




    # - name: model.layers.25.input_layernorm
    # - name: model.layers.24.input_layernorm

train:
  do_train: true
  epochs: 100
  batch_size: 1
  lr: 0.0001
  num_workers: 0